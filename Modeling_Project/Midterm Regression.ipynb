{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f4573615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import getpass\n",
    "import sqlalchemy as sa\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder  ##. better to use dummy from pandas \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.feature_selection import RFE\n",
    "pd.options.display.max_rows = 50\n",
    "## Install xlrd package to load Excel files\n",
    "# conda install openpyxl\n",
    "## conda install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613dccbd",
   "metadata": {},
   "source": [
    "## Importing Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "71384a3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hp_df_org = pd.read_csv('C:/Users/Lenovo/Documents/GitHub/Houseprices/Data/house_price_df.csv')\n",
    "hp_df = hp_df_org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e1483",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "493a5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     21597 non-null  int64  \n",
      " 1   id             21597 non-null  int64  \n",
      " 2   date           21597 non-null  object \n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     21597 non-null  int64  \n",
      " 9   view           21597 non-null  int64  \n",
      " 10  condition      21597 non-null  int64  \n",
      " 11  grade          21597 non-null  int64  \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  int64  \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   21597 non-null  int64  \n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      " 21  price          21597 non-null  int64  \n",
      "dtypes: float64(4), int64(17), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "hp_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba015ee1",
   "metadata": {},
   "source": [
    "The Dataset consists of 21597 Houses containing 21 features. Price is to be the predicted variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "3aabbcb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>...</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21597.000000</td>\n",
       "      <td>2.159700e+04</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>2.159700e+04</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>2.159700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10798.000000</td>\n",
       "      <td>4.580474e+09</td>\n",
       "      <td>3.373200</td>\n",
       "      <td>2.115826</td>\n",
       "      <td>2080.321850</td>\n",
       "      <td>1.509941e+04</td>\n",
       "      <td>1.494096</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.234292</td>\n",
       "      <td>3.409825</td>\n",
       "      <td>...</td>\n",
       "      <td>1788.596842</td>\n",
       "      <td>291.725008</td>\n",
       "      <td>1970.999676</td>\n",
       "      <td>84.464787</td>\n",
       "      <td>98077.951845</td>\n",
       "      <td>47.560093</td>\n",
       "      <td>-122.213982</td>\n",
       "      <td>1986.620318</td>\n",
       "      <td>12758.283512</td>\n",
       "      <td>5.402966e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6234.661218</td>\n",
       "      <td>2.876736e+09</td>\n",
       "      <td>0.926299</td>\n",
       "      <td>0.768984</td>\n",
       "      <td>918.106125</td>\n",
       "      <td>4.141264e+04</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.086549</td>\n",
       "      <td>0.766390</td>\n",
       "      <td>0.650546</td>\n",
       "      <td>...</td>\n",
       "      <td>827.759761</td>\n",
       "      <td>442.667800</td>\n",
       "      <td>29.375234</td>\n",
       "      <td>401.821438</td>\n",
       "      <td>53.513072</td>\n",
       "      <td>0.138552</td>\n",
       "      <td>0.140724</td>\n",
       "      <td>685.230472</td>\n",
       "      <td>27274.441950</td>\n",
       "      <td>3.673681e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>7.800000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5399.000000</td>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1430.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471100</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>3.220000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10798.000000</td>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.231000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "      <td>4.500000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16197.000000</td>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068500e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "      <td>6.450000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21596.000000</td>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "      <td>7.700000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0            id      bedrooms     bathrooms   sqft_living  \\\n",
       "count  21597.000000  2.159700e+04  21597.000000  21597.000000  21597.000000   \n",
       "mean   10798.000000  4.580474e+09      3.373200      2.115826   2080.321850   \n",
       "std     6234.661218  2.876736e+09      0.926299      0.768984    918.106125   \n",
       "min        0.000000  1.000102e+06      1.000000      0.500000    370.000000   \n",
       "25%     5399.000000  2.123049e+09      3.000000      1.750000   1430.000000   \n",
       "50%    10798.000000  3.904930e+09      3.000000      2.250000   1910.000000   \n",
       "75%    16197.000000  7.308900e+09      4.000000      2.500000   2550.000000   \n",
       "max    21596.000000  9.900000e+09     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.159700e+04  21597.000000  21597.000000  21597.000000  21597.000000   \n",
       "mean   1.509941e+04      1.494096      0.007547      0.234292      3.409825   \n",
       "std    4.141264e+04      0.539683      0.086549      0.766390      0.650546   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068500e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "       ...    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  ...  21597.000000   21597.000000  21597.000000  21597.000000   \n",
       "mean   ...   1788.596842     291.725008   1970.999676     84.464787   \n",
       "std    ...    827.759761     442.667800     29.375234    401.821438   \n",
       "min    ...    370.000000       0.000000   1900.000000      0.000000   \n",
       "25%    ...   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%    ...   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%    ...   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max    ...   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \\\n",
       "count  21597.000000  21597.000000  21597.000000   21597.000000   21597.000000   \n",
       "mean   98077.951845     47.560093   -122.213982    1986.620318   12758.283512   \n",
       "std       53.513072      0.138552      0.140724     685.230472   27274.441950   \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000   \n",
       "25%    98033.000000     47.471100   -122.328000    1490.000000    5100.000000   \n",
       "50%    98065.000000     47.571800   -122.231000    1840.000000    7620.000000   \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000   \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000   \n",
       "\n",
       "              price  \n",
       "count  2.159700e+04  \n",
       "mean   5.402966e+05  \n",
       "std    3.673681e+05  \n",
       "min    7.800000e+04  \n",
       "25%    3.220000e+05  \n",
       "50%    4.500000e+05  \n",
       "75%    6.450000e+05  \n",
       "max    7.700000e+06  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decc53c",
   "metadata": {},
   "source": [
    "The average house has about 3 bedrooms, 2080 sqft of living area, a lot size of 15000 sqft, was built in 1970 and has a price of 540000 $. The mean and the median differ alot in the variable sqft lot, where the median is much lower then the mean. This leads to the conculusion that many houses don't have a big lot but a few house with a big lot change the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c59b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(hp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730bf39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hp_df['date'].min(), hp_df['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7890bf7",
   "metadata": {},
   "source": [
    "The date variable displays the date when the house was sold. Data is between May 2014 and May 2015. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a3815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b73fd",
   "metadata": {},
   "source": [
    "Most houses have 2,5 bathrooms, a lot also only . A view outliers have a very high number of bathrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c93e42",
   "metadata": {},
   "source": [
    "## Location\n",
    "\n",
    "For the location the datasets offers three features. Latitute and Longitude (only useful combined) and zipcodes. Let's look at both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c592eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " sns.scatterplot(data=hp_df, x='long', y='lat', hue = 'waterfront').set(title='Houses at waterfront')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4385a7e",
   "metadata": {},
   "source": [
    "Looking at the geographical location of the houses and displaying the lot size it is visual, that the properties at the are outskirts and the countryside get bigger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83796a34",
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.scatterplot(data=hp_df, x='long', y='lat', hue = 'zipcode').set(title='Zipcode and geographical location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b240be6c",
   "metadata": {},
   "source": [
    "The zipcodes are not in a logical order so the variables should not be used as a numerical variables.\n",
    "And alternative idea would be to use the travel distance from the house to the city center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = pd.read_csv('C:/Users/Lenovo/Documents/GitHub/Houseprices/Data/distance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643851d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['distanceM'] = distance['DistanceM'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=hp_df, x='long', y='lat', hue = 'distanceM').set(title='Geographical location and distance to citycenter by car')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c558344",
   "metadata": {},
   "source": [
    "## Year renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34be705",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=hp_df, x='yr_renovated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48680aaf",
   "metadata": {},
   "source": [
    "The year renovated displays a 0 if the house was not yet renovated. This is not useful information in a linear regression. \n",
    "\n",
    "Workaround:\n",
    "\n",
    "introduce boolean variable: Renovated: Yes/N0\n",
    "Put zero values as No  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['renovated'] = bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['yr_renovated'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2bcb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp_df.loc[hp_df['yr_renovated'] == 0, 'renovated'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b43371",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.loc[hp_df['yr_renovated'] != 0, 'renovated'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb56f67",
   "metadata": {},
   "source": [
    "## Basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6306aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=hp_df, x='sqft_basement')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07907b25",
   "metadata": {},
   "source": [
    "Most Houses don't have a basement, so a dummy will be introduced checking for basement or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c377a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.loc[hp_df['sqft_basement'] == 0, 'basement'] = False\n",
    "hp_df.loc[hp_df['sqft_basement'] != 0, 'basement'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c0b8d",
   "metadata": {},
   "source": [
    "## Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee487a25",
   "metadata": {},
   "source": [
    "Bin grade to have a better classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c52dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_mean = hp_df['grade'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77155c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(hp_df)):\n",
    "    if hp_df['grade'][i]<grade_mean:\n",
    "        hp_df['grade'][i] = 'below_avg'\n",
    "    else:\n",
    "        hp_df['grade'][i] = 'avg_or_better'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(hp_df['grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a3bfd",
   "metadata": {},
   "source": [
    "## Floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d882a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(hp_df['floors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['floors'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a550e9",
   "metadata": {},
   "source": [
    "bin floors to be more equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1589017",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(hp_df)):\n",
    "    if hp_df.loc[i, 'floors'] <= 1.0:\n",
    "        hp_df.loc[i,'floors'] = 'one'\n",
    "    else: \n",
    "        hp_df.loc[i, 'floors'] = 'more_than_one'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(hp_df['floors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca0b83",
   "metadata": {},
   "source": [
    "## Dropping columns:\n",
    "\n",
    "For now the columns Unnamed, id, date and long, lat will be dropped from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop = ['Unnamed: 0',\\\n",
    "            'id',\\\n",
    "            'date',\\\n",
    "           'long',\\\n",
    "            'sqft_basement',\\\n",
    "            'yr_renovated',\\\n",
    "           'lat']   \n",
    "# 'Unnamed: 0' : id from import without information\n",
    "# 'id': random or consequtive values without values\n",
    "# 'date': probably the date the house was added to the database, no additional information for houseprice\n",
    "# 'lang', 'lat': Geografical data, not usable in linear regression like this, can be converted to zones using knn. \n",
    "#    Task for later. But zip codes are enough, probably\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57635f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df = hp_df.drop(col_drop, axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff110eef",
   "metadata": {},
   "source": [
    "## Changing datatypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6dd6e1",
   "metadata": {},
   "source": [
    "The format of the features are mostly numerical (int or float). Many of the variables have to be transformed to category to give meaningful results in a regression.\n",
    "These are:\n",
    "\n",
    "'zipcode, 'bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62cf06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the pairplot we can see which columns are categorical/dummies:\n",
    "#  bderooms, bathrooms, floors, waterfront, view, condition, grade\n",
    "ordinal_var = ['zipcode', 'floors', 'waterfront', 'view', 'condition', 'grade']\n",
    "hp_df[ordinal_var] = hp_df[ordinal_var].astype('category')\n",
    "hp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91c783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fafbb",
   "metadata": {},
   "source": [
    "## Checking correlation of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc4753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = hp_df.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(9, 7))\n",
    "    ax = sns.heatmap(corr, mask=mask,cmap='coolwarm', vmin=-1,vmax=1,annot=True, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598a819",
   "metadata": {},
   "source": [
    "The features should not be correlated in order to fulfill the asumtions of linear regression.\n",
    "As expected there is a lot of correlation between sqf_above, sqf_living and other measures of size. \n",
    "- First: Drop sqf_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=hp_df.corr().abs()\n",
    "upper_triangle=corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(bool))\n",
    "corr_var = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.80)]\n",
    "hp_df = hp_df.drop(corr_var, axis= 1)\n",
    "hp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22505d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = hp_df.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(9, 7))\n",
    "    ax = sns.heatmap(corr, mask=mask,cmap='coolwarm', vmin=-1,vmax=1,annot=True, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9cf9b",
   "metadata": {},
   "source": [
    "The new dataframe does not contain anymore variables with a higher correlation than 0.8, but some variable still have high correlation which could be analysed later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ceba64",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a9e89b",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "To check for the assumtion of normal distributions we check the histograms of the numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377572f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp_df.select_dtypes(['int64','float']).hist(figsize=(12,12), bins=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d208350",
   "metadata": {},
   "source": [
    "All numerical varibales are non-normaly distributed and need to be transformed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9192c43",
   "metadata": {},
   "source": [
    "## Transforming to normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd80908",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.select_dtypes(['int64','float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12465832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables names to be transformed: \n",
    "to_trans =  {'sqft_living': 'qt',\\\n",
    "             'sqft_lot': 'qt',\\\n",
    "             'yr_built': 'qt',\\\n",
    "             'sqft_living15': 'qt',\\\n",
    "             'sqft_lot15': 'qt',\\\n",
    "            'bedrooms': 'qt',\\\n",
    "            'bathrooms': 'qt',\\\n",
    "            'distanceM': 'qt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273bb0d",
   "metadata": {},
   "source": [
    "For the transformation of the variables the Quantile Transformer is applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab4152",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pt = PowerTransformer()\n",
    "qt = QuantileTransformer(output_distribution=\"normal\")\n",
    "\n",
    "transformed_cols = []\n",
    "for i in to_trans.keys():\n",
    "    if list(to_trans.values())[0] == 'pt':\n",
    "        transformed = pt.fit_transform(hp_df[i].to_numpy().reshape(-1,1))\n",
    "    elif list(to_trans.values())[0] == 'qt':\n",
    "        transformed = qt.fit_transform(hp_df[i].to_numpy().reshape(-1,1))\n",
    "    else: \n",
    "        print('no transformer could be identified')\n",
    "    col_name = i+'_transformed'\n",
    "    sns.displot(transformed).set(title=f'Histogram of {col_name}')\n",
    "    hp_df[col_name] = transformed\n",
    "    transformed_cols = transformed_cols + [col_name]\n",
    "    hp_df = hp_df.drop(i, axis= 1)\n",
    "    \n",
    "    \n",
    "hp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816fe0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp_df.select_dtypes(['int', 'float64']).hist(figsize=(12,12), bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc6dd2",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226f5b3",
   "metadata": {},
   "source": [
    "The Datasets contains a few datapoints that can described as outliers. One house for example as 33 rooms while the average amount of rooms is around 3. Using the two time the Interquartile range whe remove the outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in transformed_cols:\n",
    "    sns.boxplot(data=hp_df[transformed_cols]).set(title='Boxplots of numerical variables showing outliers')\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775308b7",
   "metadata": {},
   "outputs": [],
   "source": [
    " len_before = hp_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-2*iqr\n",
    "    fence_high = q3+2*iqr\n",
    "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "    return df_out\n",
    "\n",
    "#for i in transformed_cols: \n",
    "hp_df = remove_outlier(hp_df, i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f276cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in transformed_cols:\n",
    "    sns.boxplot(data=hp_df[transformed_cols]).set(title='Boxplots of numerical variables showing outliers')\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_after = hp_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaea842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Of the original dataset {round(len_after/len_before * 100, 2)}% of rows remain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36274778",
   "metadata": {},
   "source": [
    "## One-hot encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_object = list(hp_df.select_dtypes(\"object\").columns)\n",
    "col_names_object.extend(hp_df.select_dtypes(\"category\").columns)\n",
    "col_names_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features =  pd.get_dummies(hp_df[col_names_object] , drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df = hp_df.drop(col_names_object, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0253b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df[cat_features.columns] = cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ffbf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(hp_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b47f885",
   "metadata": {},
   "source": [
    "## 1st Model only using numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c36cb",
   "metadata": {},
   "source": [
    "###  1) Split X-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec4769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=hp_df.drop('price', axis=1)\n",
    "y=hp_df['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1296b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1524ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(cat_features.columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d047396",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=.30,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae569673",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ea548",
   "metadata": {},
   "source": [
    "### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bcdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler=StandardScaler().fit(X_train)   ##. finding the parameters ( mean, variance from the training set )\n",
    "                                            ## \n",
    "X_train_scaled=std_scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled=std_scaler.transform(X_test)\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc28250",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_const_scaled = sm.add_constant(X_train_scaled) # adding a constant\n",
    "\n",
    "model = sm.OLS(y_train, X_train_const_scaled).fit()\n",
    "predictions_train = model.predict(X_train_const_scaled) \n",
    "\n",
    "X_test_const_scaled = sm.add_constant(X_test_scaled) # adding a constant\n",
    "predictions_test = model.predict(X_test_const_scaled) \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34169886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=LinearRegression()    # model\n",
    "model.fit(X_train_scaled, y_train)   # model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b47555",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test_scaled)   # model prediction\n",
    "\n",
    "y_pred_train=model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b356ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result=pd.DataFrame({\"y_test\":y_test,\"y_pred\":y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an scatter plot y_pred vs y\n",
    "# What kind of plot you will get if all the all the predictions are ok?\n",
    "# A stright line\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(14,4))\n",
    "ax[0].plot(y_pred, y_test, 'o')\n",
    "ax[0].set_xlabel(\"y_test\")\n",
    "ax[0].set_ylabel(\"y_pred\")\n",
    "ax[0].set_title(\"Test Set -Predicted vs real\")\n",
    "\n",
    "# Get a histogram of the residuals ie: y - y_pred.  Homoscdasticity\n",
    "# It resembles a normal distribution?\n",
    "ax[1].hist(y_test - y_pred)\n",
    "ax[1].set_xlabel(\"Test y-y_pred\")\n",
    "ax[1].set_title(\"Test Set Residual histogram\")\n",
    "\n",
    "ax[2].plot(y_pred,y_test - y_pred,\"o\")\n",
    "ax[2].set_xlabel(\"predicted\")\n",
    "ax[2].set_ylabel(\"residuals\")\n",
    "ax[2].set_title(\"Residuals by Predicted\")\n",
    "ax[2].plot(y_pred,np.zeros(len(y_pred)),linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb60cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('MSE test: ',  mse(y_test,y_pred))\n",
    "print('MAE test: ', mae(y_test,y_pred))\n",
    "print('MSE train: ', mse(y_train,y_pred_train))\n",
    "print('RMSE test: ', np.sqrt(mae(y_test,y_pred)))\n",
    "R2_test=model.score(X_test_scaled,y_test)\n",
    "R2_train=model.score(X_train_scaled,y_train)\n",
    "print('R2_test: ', R2_test)\n",
    "print('R2_train: ', R2_train)\n",
    "\n",
    "print('MSE train - MSE test: ', mse(y_train,y_pred_train) - mse(y_test,y_pred) )\n",
    "print('R2_test/R2_train: ', R2_test/R2_train )\n",
    "Adj_R2= 1 - (1-R2_test)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "print('Adj_R2:', Adj_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': abs(model.coef_)\n",
    "})\n",
    "features_importances = features_importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46fcc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=features_importances['Attribute'], height=features_importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9d3c1",
   "metadata": {},
   "source": [
    "## 2nd model including categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xy_split(df, output_col):\n",
    "    \"\"\" Split the dataset into:\n",
    "        X = dataframe of input variables\n",
    "        y = predicted variable\n",
    "    \"\"\"\n",
    "    X=df.drop(output_col, axis=1)\n",
    "    y=df[output_col]\n",
    "    print(X.columns)\n",
    "    return X, y\n",
    "\n",
    "X,y = Xy_split(hp_df, 'price') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=.30,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler=StandardScaler().fit(X_train.select_dtypes(['int', 'float64']))   ##. finding the parameters ( mean, variance from the training set )\n",
    "                                            ## \n",
    "X_train_scaled=std_scaler.transform(X_train.select_dtypes(['int', 'float64']))\n",
    "\n",
    "X_test_scaled=std_scaler.transform(X_test.select_dtypes(['int', 'float64']))\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df85e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = np.concatenate((X_train_scaled, np.asarray(X_train[list(cat_features.columns)])), axis = 1) \n",
    "\n",
    "X_test_scaled = np.concatenate((X_test_scaled, np.asarray(X_test[list(cat_features.columns)])), axis =1)\n",
    "print(X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04026b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2860c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model=LinearRegression()    # model\n",
    "model.fit(X_train_scaled, y_train) \n",
    "\n",
    "\n",
    "y_pred=model.predict(X_test_scaled)   # model prediction\n",
    "y_pred_train=model.predict(X_train_scaled)\n",
    "\n",
    "\n",
    "result=pd.DataFrame({\"y_test\":y_test,\"y_pred\":y_pred})\n",
    "\n",
    "\n",
    "# Make an scatter plot y_pred vs y\n",
    "# What kind of plot you will get if all the all the predictions are ok?\n",
    "# A stright line\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(14,4))\n",
    "ax[0].plot(y_pred, y_test, 'o')\n",
    "ax[0].set_xlabel(\"y_test\")\n",
    "ax[0].set_ylabel(\"y_pred\")\n",
    "ax[0].set_title(\"Test Set -Predicted vs real\")\n",
    "\n",
    "# Get a histogram of the residuals ie: y - y_pred.  Homoscdasticity\n",
    "# It resembles a normal distribution?\n",
    "ax[1].hist(y_test - y_pred)\n",
    "ax[1].set_xlabel(\"Test y-y_pred\")\n",
    "ax[1].set_title(\"Test Set Residual histogram\")\n",
    "\n",
    "ax[2].plot(y_pred,y_test - y_pred,\"o\")\n",
    "ax[2].set_xlabel(\"predicted\")\n",
    "ax[2].set_ylabel(\"residuals\")\n",
    "ax[2].set_title(\"Residuals by Predicted\")\n",
    "ax[2].plot(y_pred,np.zeros(len(y_pred)),linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f412a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.jointplot(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd46ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.jointplot(x=y_pred,y = (y_test - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ab2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE test: ',  mse(y_test,y_pred))\n",
    "print('MAE test: ', mae(y_test,y_pred))\n",
    "print('MSE train: ', mse(y_train,y_pred_train))\n",
    "print('RMSE test: ', np.sqrt(mae(y_test,y_pred)))\n",
    "R2_test=model.score(X_test_scaled,y_test)\n",
    "R2_train=model.score(X_train_scaled,y_train)\n",
    "print('R2_test: ', R2_test)\n",
    "print('R2_train: ', R2_train)\n",
    "\n",
    "print('MSE train - MSE test: ', mse(y_train,y_pred_train) - mse(y_test,y_pred) )\n",
    "print('R2_test/R2_train: ', R2_test/R2_train )\n",
    "Adj_R2= 1 - (1-R2_test)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "print('Adj_R2:', Adj_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9153175",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': abs(model.coef_)\n",
    "})\n",
    "features_importances = features_importances.sort_values(by='Importance', ascending=False)\n",
    "features_importances\n",
    "plt.bar(x=features_importances['Attribute'], height=features_importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.figure(figsize=(200, 200), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances.nlargest(20, 'Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78649710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a8030c3",
   "metadata": {},
   "source": [
    "## Get P-values from model \n",
    "\n",
    "To filter the significant columns we get the p-value from the linear regression. If it is higher than 0.5 the column is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8758bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_const_scaled = sm.add_constant(X_train_scaled) # adding a constant\n",
    "\n",
    "model = sm.OLS(y_train, X_train_const_scaled).fit()\n",
    "predictions_train = model.predict(X_train_const_scaled) \n",
    "\n",
    "X_test_const_scaled = sm.add_constant(X_test_scaled) # adding a constant\n",
    "predictions_test = model.predict(X_test_const_scaled) \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_cols = model.pvalues[1:len(model.pvalues)]  # remove constant\n",
    "\n",
    "sign_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82bf5bb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Pseudo-Code: for i in range(0, len(X.column)) drop X.columns[i] if sign_cols[i]> 0.05\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5189878",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_cols = pd.DataFrame([sign_cols])\n",
    "sign_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd88a05d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_col_list = X.columns\n",
    "X_dropped_p = X\n",
    "for i in range(0,len(X.columns)):\n",
    "    if sign_cols.iloc[0,i]>0.05:\n",
    "        X_dropped_p = X_dropped_p.drop(X_col_list[i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48073746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'From orginally {X.shape[1]} features {X_dropped_p.shape[1]} features remain.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1530207",
   "metadata": {},
   "source": [
    "## 3d linear Model only including variabels that had a siginificant p-value in the 2s Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46dc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X_dropped_p, y, test_size=.30,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(['float64'])\n",
    "X_test_num = X_test.select_dtypes(['float64'])\n",
    "X_train_cat = X_train.select_dtypes(['uint8'])\n",
    "X_test_cat = X_test.select_dtypes(['uint8'])\n",
    "print(X_train_num.shape, X_test_num.shape, X_train_cat.shape, X_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler=StandardScaler().fit(X_train_num)   ##. finding the parameters ( mean, variance from the training set )\n",
    "                                            ## \n",
    "X_train_scaled=std_scaler.transform(X_train_num)\n",
    "\n",
    "X_test_scaled=std_scaler.transform(X_test_num)\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = np.concatenate((X_train_scaled, np.asarray(X_train_cat)), axis = 1) \n",
    "\n",
    "X_test_scaled = np.concatenate((X_test_scaled, np.asarray(X_test_cat)), axis =1)\n",
    "print(X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c68579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegression()    # model\n",
    "model.fit(X_train_scaled, y_train) \n",
    "\n",
    "\n",
    "y_pred=model.predict(X_test_scaled)   # model prediction\n",
    "y_pred_train=model.predict(X_train_scaled)\n",
    "\n",
    "\n",
    "result=pd.DataFrame({\"y_test\":y_test,\"y_pred\":y_pred})\n",
    "\n",
    "\n",
    "# Make an scatter plot y_pred vs y\n",
    "# What kind of plot you will get if all the all the predictions are ok?\n",
    "# A stright line\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(14,4))\n",
    "ax[0].plot(y_pred, y_test, 'o')\n",
    "ax[0].set_xlabel(\"y_test\")\n",
    "ax[0].set_ylabel(\"y_pred\")\n",
    "ax[0].set_title(\"Test Set -Predicted vs real\")\n",
    "\n",
    "# Get a histogram of the residuals ie: y - y_pred.  Homoscdasticity\n",
    "# It resembles a normal distribution?\n",
    "ax[1].hist(y_test - y_pred)\n",
    "ax[1].set_xlabel(\"Test y-y_pred\")\n",
    "ax[1].set_title(\"Test Set Residual histogram\")\n",
    "\n",
    "ax[2].plot(y_pred,y_test - y_pred,\"o\")\n",
    "ax[2].set_xlabel(\"predicted\")\n",
    "ax[2].set_ylabel(\"residuals\")\n",
    "ax[2].set_title(\"Residuals by Predicted\")\n",
    "ax[2].plot(y_pred,np.zeros(len(y_pred)),linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84382604",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE test: ',  mse(y_test,y_pred))\n",
    "print('MAE test: ', mae(y_test,y_pred))\n",
    "print('MSE train: ', mse(y_train,y_pred_train))\n",
    "print('RMSE test: ', np.sqrt(mae(y_test,y_pred)))\n",
    "R2_test=model.score(X_test_scaled,y_test)\n",
    "R2_train=model.score(X_train_scaled,y_train)\n",
    "print('R2_test: ', R2_test)\n",
    "print('R2_train: ', R2_train)\n",
    "\n",
    "print('MSE train - MSE test: ', mse(y_train,y_pred_train) - mse(y_test,y_pred) )\n",
    "print('R2_test/R2_train: ', R2_test/R2_train )\n",
    "Adj_R2= 1 - (1-R2_test)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "print('Adj_R2:', Adj_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42908e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': abs(model.coef_)\n",
    "})\n",
    "features_importances = features_importances.sort_values(by='Importance', ascending=False)\n",
    "features_importances\n",
    "plt.bar(x=features_importances['Attribute'], height=features_importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances #.nlargest(30, 'Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6555e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances.to_csv('C:/Users/Lenovo/Documents/GitHub/Houseprices/Data/final_model_feature_importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066f4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_const_scaled = sm.add_constant(X_train_scaled) # adding a constant\n",
    "\n",
    "model = sm.OLS(y_train, X_train_const_scaled).fit()\n",
    "predictions_train = model.predict(X_train_const_scaled) \n",
    "\n",
    "X_test_const_scaled = sm.add_constant(X_test_scaled) # adding a constant\n",
    "predictions_test = model.predict(X_test_const_scaled) \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710ab98",
   "metadata": {},
   "source": [
    "## Visualizing results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01384df3",
   "metadata": {},
   "source": [
    "Zip-code showed to be very determining for prices. The zipcode 98039 showed to show the highest price effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_grouped_by_zipcode = hp_df_org.groupby('zipcode').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_grouped_by_zipcode.drop(['Unnamed: 0', 'id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_grouped_by_zipcode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(avg_grouped_by_zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=avg_grouped_by_zipcode, x='long', y='lat', hue='bathrooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=avg_grouped_by_zipcode, x='long', y='lat', hue='zipcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a890d",
   "metadata": {},
   "source": [
    "Filtering for postcode with biggest influence: 98039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d822399",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode98039 = hp_df_org[hp_df_org['zipcode']==98039]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f75f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=zipcode98039, x='long', y='lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode98004 = hp_df_org[hp_df_org['zipcode']==98004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642eface",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "waterfront1 = hp_df_org[hp_df_org['waterfront']==1]\n",
    "waterfront1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b56852",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=waterfront1, x='long', y='lat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141d067",
   "metadata": {},
   "source": [
    "Get Map background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56039b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import contextily as cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vplot(df, xax_var, yax_var, split_var):\n",
    "    '''\n",
    "    Function to create a violin plot with given variables\n",
    "    xax_var = 'sales_channel' # Categorical variable to show along the x-axis\n",
    "    yax_var = 'total_claim_amount' # Numerical Variable to show along the y-axis\n",
    "    split_var = 'response' #Boolean variable to display on each half of the violins\n",
    "    '''\n",
    "    return sns.violinplot(x =df[xax_var],\\\n",
    "                        y = yax_var,\\\n",
    "                        hue=split_var,\\\n",
    "                        data= hp_df_org, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07309b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xax_var = 'view' # Categorical variable to show along the x-axis\n",
    "yax_var = 'price' # Numerical Variable to show along the y-axis\n",
    "split_var = 'waterfront' #Boolean variable to display on each half of the violins\n",
    "vplot(hp_df_org, xax_var, yax_var, split_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407b6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xax_var = 'waterfront' # Categorical variable to show along the x-axis\n",
    "yax_var = 'price' # Numerical Variable to show along the y-axis\n",
    "split_var = 'view' #Boolean variable to display on each half of the violins\n",
    "vplot(hp_df_org, xax_var, yax_var, split_var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
